{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b77336-9306-40bf-9d3e-395b95fd7fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:13:41.730532Z",
     "start_time": "2025-03-23T06:13:35.013406Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Notebook Name: Generate_CoT_Sentiment_Analysis.ipynb\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset, Value\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08c7b35-7d9a-4ed1-a97e-ad223aacb851",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\zjt20\\.conda\\envs\\new_env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "\n",
    "# 在代码开头添加正确的导入\n",
    "from openai import OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7decacf5-dc3d-42c8-8e38-b33281dab2ba",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a685c32d-bce3-4eea-a639-7fa0cc2a1f63",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle_secrets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load API keys from Kaggle Secrets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkaggle_secrets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UserSecretsClient\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_kaggle_secrets\u001b[39m():\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    Load API keys from Kaggle Secrets.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kaggle_secrets'"
     ]
    }
   ],
   "source": [
    "# Load API keys from Kaggle Secrets\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "\n",
    "def load_kaggle_secrets():\n",
    "    \"\"\"\n",
    "    Load API keys from Kaggle Secrets.\n",
    "    \"\"\"\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"DeepSeek_API_KEY\")\n",
    "    hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "    return api_key, hf_token\n",
    "\n",
    "\n",
    "# Load API keys\n",
    "api_key, hf_token = load_kaggle_secrets()\n",
    "\n",
    "# Ensure API keys are available\n",
    "if not api_key or not hf_token:\n",
    "    raise ValueError(\"Missing API keys! Add 'DeepSeek_API_KEY' and 'HF_TOKEN' to your Kaggle Secrets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec88fdda-fa1a-46b8-a07a-cb9449adaff9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:13:41.769771Z",
     "start_time": "2025-03-23T06:13:41.753330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to initialize the API client\n",
    "def initialize_api_client(api_key):\n",
    "    \"\"\"\n",
    "    Initialize the OpenAI client with DeepSeek API.\n",
    "    \"\"\"\n",
    "    return OpenAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://api.deepseek.com\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870b8a5-df05-4735-bda5-a7ce880ab244",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(biased_path, neutral_path):\n",
    "    \"\"\"加载带有详细元数据的偏见数据集\"\"\"\n",
    "    from datasets import Dataset\n",
    "    data = []\n",
    "    \n",
    "    # 加载偏见数据（包含完整元数据）\n",
    "    with open(biased_path, 'r', encoding='utf-8-sig') as f:\n",
    "        for item in json.load(f):\n",
    "            record = {\n",
    "                'original_text': item['ori_sentence'],\n",
    "                'edited_text': item['edit_sentence'],\n",
    "                'bias_labels': item['bias_labels'],\n",
    "                'text_type': 'biased'\n",
    "            }\n",
    "            data.append(record)\n",
    "    \n",
    "    # 加载中性数据（补充必要字段）\n",
    "    with open(neutral_path, 'r', encoding='utf-8-sig') as f:\n",
    "        for item in json.load(f):\n",
    "            record = {\n",
    "                'original_text': item['text'],\n",
    "                'edited_text': None,\n",
    "                'bias_labels': [0, 0, 0],\n",
    "                'text_type': 'neutral'\n",
    "            }\n",
    "            data.append(record)\n",
    "    \n",
    "    return Dataset.from_list(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79599df-91ce-4450-b861-6561a3de8381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:13:42.173502Z",
     "start_time": "2025-03-23T06:13:42.155873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_bias_cot(client, item, max_retries=3):\n",
    "    bias_types = [\n",
    "        \"AC（职业活动刻板印象）\",\n",
    "        \"DI（描述归纳偏见）\", \n",
    "        \"ANB（态度规范偏见）\"\n",
    "    ]\n",
    "    \n",
    "    prompt = f\"\"\"请按照以下框架分析文本的性别偏见：\n",
    "\n",
    "【任务说明】\n",
    "1. 偏见检测：判断文本是否包含性别偏见 (B/N)\n",
    "2. 偏见分类：若存在偏见，按三类标注 (AC/DI/ANB)\n",
    "3. 偏见缓解：生成无偏见的修改版本\n",
    "\n",
    "【分类标准】\n",
    "- AC (职业活动刻板印象): 将职业/活动与性别绑定 (例：\"护士应该由女性担任\")\n",
    "- DI (描述归纳偏见): 基于性别的特征归纳 (例：\"男生都不擅长文科\")\n",
    "- ANB (态度规范偏见): 传达性别不平等观念 (例：\"女孩就该文静听话\")\n",
    "\n",
    "【分析步骤】\n",
    "1. 识别所有性别相关表述\n",
    "2. 逐句分析偏见存在性\n",
    "3. 分类标记偏见类型\n",
    "4. 生成无偏见修改方案\n",
    "【示例输入】\n",
    "原始文本：{item[\"original_text\"]}。\n",
    "【期望输出】\n",
    "{{\n",
    "    \"ori_sentence\": {item[\"original_text\"]},\n",
    "    \"is_biased\": {item[\"text_type\"]},\n",
    "    \"bias_labels\": {item[\"bias_labels\"]},  # AC={item[\"bias_labels\"][0]}, DI={item[\"bias_labels\"][1]}, ANB={item[\"bias_labels\"][2]}\n",
    "    \"edit_sentence\": \"{item[\"edited_text\"]}\",\n",
    "}}\"\"\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"您是性别偏见分析专家，擅长判断性别偏见以及分类及改写性别偏见\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.4,  # 降低随机性保证分析准确性\n",
    "                max_tokens=500,\n",
    "                stream=False\n",
    "            )\n",
    "            analysis = response.choices[0].message.content.strip()\n",
    "            # print(analysis)\n",
    "            \n",
    "            # 添加结构化结论\n",
    "            conclusion_lines = [\n",
    "                f\"{bias_types[i]}: {label}\" \n",
    "                for i, label in enumerate(item['bias_labels'])\n",
    "            ]\n",
    "\n",
    "            conclusion_lines.append(f'修改方案: {item[\"edited_text\"]}')\n",
    "            \n",
    "            conclusion = \"\\n\\n结论：\\n\" + \"\\n\".join(conclusion_lines)\n",
    "            \n",
    "            return analysis + conclusion\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Attempt {attempt+1} failed, retrying...\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                print(f\"Failed after {max_retries} attempts: {str(e)}\")\n",
    "                return \"CoT generation failed\"\n",
    "    if \"结论：\" not in analysis:\n",
    "        analysis += \"\\n结论：\\n\" + \"\\n\".join(\n",
    "            [f\"{bias_types[i]}: {label}\" for i, label in enumerate(item['bias_labels'])]\n",
    "        )\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dda9bc-cc7d-4c9e-b318-e632ed8a5207",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:13:42.220771Z",
     "start_time": "2025-03-23T06:13:42.207102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_cot_to_dataset(client, dataset, sample_size=1000):\n",
    "    \"\"\"完全正确的缩进版本\"\"\"\n",
    "    # ↓ 第1级缩进（4空格）\n",
    "    if sample_size and len(dataset) > sample_size:\n",
    "        # ↓ 第2级缩进（8空格）\n",
    "        dataset = dataset.select(range(sample_size))\n",
    "    \n",
    "    # ↓ 保持第1级缩进\n",
    "    cots = []\n",
    "    for item in tqdm(dataset):\n",
    "        cot = generate_bias_cot(client, item)\n",
    "        cots.append(cot)\n",
    "    \n",
    "    # ↓↓↓ 关键修改：统一使用Bias_Analysis_CoT作为列名 ↓↓↓\n",
    "    return dataset.add_column(\"Bias_Analysis_CoT\", cots) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff4bbc-4123-4b21-b7ae-f652745821dd",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "biased_path = \"/kaggle/input/pianjian/biased.json\" \n",
    "neutral_path = \"/kaggle/input/pianjian/non-biased.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceaa162-e7f3-48be-8e28-a833b4e8cd5f",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def upload_to_huggingface(dataset, repo_id, hf_token, is_private=True):\n",
    "    \"\"\"将数据集上传到Hugging Face Hub\"\"\"\n",
    "    login(token=hf_token)\n",
    "    \n",
    "    # 确保字段名称与实际列名一致\n",
    "    dataset = dataset.cast_column(\"Bias_Analysis_CoT\", Value(\"string\"))  # 修改这里\n",
    "    \n",
    "    dataset.push_to_hub(\n",
    "        repo_id=repo_id,\n",
    "        token=hf_token,\n",
    "        private=is_private,\n",
    "        commit_message=\"Add CoT annotations\"\n",
    "    )\n",
    "    print(f\"✅ 数据集已上传至: https://huggingface.co/datasets/{repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066876fc-9ece-4c56-bc62-e7eb0d285a4f",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_cot_dataset(api_key, hf_token, dataset_name, \n",
    "                      biased_path, neutral_path, \n",
    "                      sample_size=None):  # 新增参数\n",
    "    client = initialize_api_client(api_key)\n",
    "    \n",
    "    # 加载数据\n",
    "    dataset = load_data(biased_path, neutral_path)\n",
    "    \n",
    "    # 传递sample_size给处理函数\n",
    "    enhanced_dataset = add_cot_to_dataset(\n",
    "        client=client,\n",
    "        dataset=dataset,\n",
    "        sample_size=sample_size  # 传递参数\n",
    "    )\n",
    "    \n",
    "    upload_to_huggingface(enhanced_dataset, dataset_name, hf_token)\n",
    "    return enhanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf42fe-0199-4d3e-a882-2f469811dd3d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 检查数据集是否存在\n",
    "dataset_path = \"/kaggle/input/pianjian\"\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"✅ 数据集目录存在\")\n",
    "    print(\"目录内容:\", os.listdir(dataset_path))\n",
    "else:\n",
    "    print(f\"❌ 路径错误: {dataset_path} 不存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e1000-81ce-4b63-b2ff-4ff07c8edd51",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_name = \"pianjian/pianjian-with-cot-hou\"\n",
    "enhanced_dataset = create_cot_dataset(\n",
    "    api_key=api_key,\n",
    "    hf_token=hf_token,\n",
    "    dataset_name=dataset_name,\n",
    "    biased_path=biased_path,\n",
    "    neutral_path=neutral_path,\n",
    "    sample_size=1000 # 指定处理1000条数据\n",
    ")# 修改上传函数中的列名（将Complex_CoT改为Bias_Analysis_CoT）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7c86a-d8de-4bbb-a18f-0df56a1294e4",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sample_cot = enhanced_dataset[0]['Bias_Analysis_CoT']\n",
    "print(\"\\n示例CoT分析:\\n\", sample_cot)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6888932,
     "sourceId": 11081302,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7484480,
     "sourceId": 11906089,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
